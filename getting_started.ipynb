{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import ClassLabel, Dataset\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "i = 0\n",
    "test_size = 0.15\n",
    "num_classes = 2\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "set_class_weights = False\n",
    "model_version = 'xlm-roberta-large'\n",
    "\n",
    "train = pd.read_csv(f'../data_orig_splits/train_split_{i}.csv')\n",
    "test = pd.read_csv(f'../data_orig_splits/test_split_{i}.csv')\n",
    "\n",
    "\n",
    "data_ext = pd.read_parquet('../fb_Clean_Sub.parquet')[[\"text\", \"label\"]]\n",
    "train = pd.concat([train, data_ext], axis=0)\n",
    "data_ext = pd.read_parquet('../RP-Mod-Crowd_Clean_Sub.parquet')[[\"text\", \"label\"]]\n",
    "train = pd.concat([train, data_ext], axis=0)\n",
    "data_ext = pd.read_parquet('../german_hatespeech_refugees_Clean_Sub.parquet')[[\"text\", \"label\"]]\n",
    "train = pd.concat([train, data_ext], axis=0)\n",
    "\n",
    "#pos_add = data_ext[data_ext[\"label\"] == 1]\n",
    "#neg_add = data_ext[data_ext[\"label\"] == 0]\n",
    "#neg_add = neg_add.sample(len(pos_add))\n",
    "#add_data = pd.concat([pos_add, neg_add], axis=0)\n",
    "\n",
    "train = Dataset.from_pandas(pd.DataFrame({'text': train[\"text\"], 'label': train[\"label\"]}))\n",
    "test = Dataset.from_pandas(pd.DataFrame({'text': test[\"text\"], 'label': test[\"label\"]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_version)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_version, num_labels=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992f3c190cc44d51a58204cf023f949f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30638 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5353cc70784ccba8d730d25960f477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/968 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_batch(batch):\n",
    "    tokens = tokenizer(batch['text'], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    return tokens\n",
    "   \n",
    "#     try:\n",
    "#         tokens = tokenizer(batch['text'], padding=\"max_length\", truncation=True, max_length=128)\n",
    "#    # tokens['label'] = labels.str2int(batch['label'])\n",
    "#         return tokens\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "train_tokenized = train.map(tokenize_batch, batched=True, batch_size=1000)\n",
    "test_tokenized = test.map(tokenize_batch, batched=True, batch_size=1000)\n",
    "\n",
    "train_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"f1\": f1, \"accuracy\": acc}\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=2,              # total number of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
    "#   warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=300,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=1,\n",
    "    optim='adamw_torch',\n",
    "    fp16=True,\n",
    "    learning_rate=5e-6,\n",
    "    save_strategy='steps',\n",
    "    save_steps=300\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_tokenized,         # training dataset\n",
    "    eval_dataset=test_tokenized,             # evaluation dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6301' max='7660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6301/7660 24:37 < 05:18, 4.26 it/s, Epoch 1.64/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.657510</td>\n",
       "      <td>0.639076</td>\n",
       "      <td>0.612603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.697900</td>\n",
       "      <td>0.599785</td>\n",
       "      <td>0.642202</td>\n",
       "      <td>0.677686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.697900</td>\n",
       "      <td>0.579673</td>\n",
       "      <td>0.743979</td>\n",
       "      <td>0.703512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.613624</td>\n",
       "      <td>0.736756</td>\n",
       "      <td>0.666322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.607600</td>\n",
       "      <td>0.565890</td>\n",
       "      <td>0.734109</td>\n",
       "      <td>0.693182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.607600</td>\n",
       "      <td>0.543381</td>\n",
       "      <td>0.764331</td>\n",
       "      <td>0.732438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.590600</td>\n",
       "      <td>0.547132</td>\n",
       "      <td>0.763508</td>\n",
       "      <td>0.724174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.590600</td>\n",
       "      <td>0.539134</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.746901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.581000</td>\n",
       "      <td>0.521236</td>\n",
       "      <td>0.773946</td>\n",
       "      <td>0.756198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.573500</td>\n",
       "      <td>0.538113</td>\n",
       "      <td>0.774368</td>\n",
       "      <td>0.741736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.573500</td>\n",
       "      <td>0.517059</td>\n",
       "      <td>0.780622</td>\n",
       "      <td>0.752066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.566700</td>\n",
       "      <td>0.505797</td>\n",
       "      <td>0.788335</td>\n",
       "      <td>0.767562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.566700</td>\n",
       "      <td>0.493491</td>\n",
       "      <td>0.776058</td>\n",
       "      <td>0.775826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.549700</td>\n",
       "      <td>0.548977</td>\n",
       "      <td>0.784560</td>\n",
       "      <td>0.752066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.504500</td>\n",
       "      <td>0.515817</td>\n",
       "      <td>0.788280</td>\n",
       "      <td>0.768595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.504500</td>\n",
       "      <td>0.522660</td>\n",
       "      <td>0.784995</td>\n",
       "      <td>0.757231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.494400</td>\n",
       "      <td>0.494444</td>\n",
       "      <td>0.793834</td>\n",
       "      <td>0.778926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.494400</td>\n",
       "      <td>0.543259</td>\n",
       "      <td>0.790571</td>\n",
       "      <td>0.761364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.505800</td>\n",
       "      <td>0.497671</td>\n",
       "      <td>0.786982</td>\n",
       "      <td>0.776860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.512600</td>\n",
       "      <td>0.527990</td>\n",
       "      <td>0.787659</td>\n",
       "      <td>0.758264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.512600</td>\n",
       "      <td>0.493417</td>\n",
       "      <td>0.795344</td>\n",
       "      <td>0.782025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), f\"models/{model_version}_079__128_large_ds.pth\")\n",
    "model.load_state_dict(torch.load(f\"models/{model_version}_079_128_large_ds.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "eval_dataloader = DataLoader(test_tokenized, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models_to_load = [\"roberta_large_v1_0779.pth\"]\n",
    "\n",
    "\n",
    "for i, model_name in enumerate(models_to_load):\n",
    "    model.load_state_dict(torch.load(f\"models/{model_name}\"))\n",
    "\n",
    "    pred_probas = np.empty((0, 2))\n",
    "\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "        y_pred_proba = torch.softmax(logits, axis=1).cpu().numpy()\n",
    "        pred_probas = np.vstack((pred_probas, y_pred_proba))\n",
    "\n",
    "    if i == 0:\n",
    "        all_preds = y_pred_proba\n",
    "    else:\n",
    "        all_preds += y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03336831, 0.96663171],\n",
       "       [0.92703366, 0.0729663 ],\n",
       "       [0.97104686, 0.02895316],\n",
       "       [0.03079216, 0.96920782],\n",
       "       [0.98423058, 0.0157694 ],\n",
       "       [0.05281403, 0.94718599],\n",
       "       [0.0298448 , 0.97015518],\n",
       "       [0.18469398, 0.81530607]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 0 and the array at index 1 has size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_probas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_proba\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hackathon/lib/python3.10/site-packages/numpy/core/shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    288\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[0;32m--> 289\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, casting\u001b[39m=\u001b[39;49mcasting)\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 0 and the array at index 1 has size 2"
     ]
    }
   ],
   "source": [
    "np.vstack((pred_probasa, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = torch.softmax(logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7762191048764197"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = test_tokenized[\"label\"].numpy()\n",
    "f1_score(y_true, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(preds, predictions.cpu().numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('hackathon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07757baf4ed5a317d6d3c7d2e760ae13735d19131b8d80240feb9e4138f8f91d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
